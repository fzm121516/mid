% !Mode:: "TeX:UTF-8"


@article{ ZGTB202402013,
author = { 冯才博 and  刘春晓 and  王昱烨 and  周其当 },
title = {结合图像块比较与残差图估计的人脸伪造检测},
journal = {中国图象图形学报},
volume = {29},
number = {02},
pages = {457-467},
year = {2024},
issn = {1006-8961},
}

@article{ XING202404001,
author = { 孙鹏 and  童世博 },
title = {面向图像与视频的AI篡改防御技术综述},
journal = {中国刑警学院学报},
volume = {},
number = {04},
pages = {5-13},
year = {2024},
issn = {2095-7939},
doi = {10.14060/j.issn.2095-7939.2024.04.001}
}


@article{ NJSH202401011,
author = { 胡泳 },
title = {人工智能驱动的虚假信息：现在与未来},
journal = {南京社会科学},
volume = {},
number = {01},
pages = {96-109},
year = {2024},
issn = {1001-8263},
doi = {10.15937/j.cnki.issn1001-8263.2024.01.011}
}


@article{ GGXB202203002,
author = { 刘国柱 },
title = {深度伪造与国家安全:基于总体国家安全观的视角},
journal = {国际安全研究},
volume = {40},
number = {03},
pages = {3-31+157},
year = {2022},
issn = {2095-574X},
doi = {10.14093/j.cnki.cn10-1132/d.2022.03.001}
}

@article{ TXBM201910007,
author = { 龙坤 and  马钺 and  朱启超 },
title = {深度伪造对国家安全的挑战及应对},
journal = {信息安全与通信保密},
volume = {},
number = {10},
pages = {21-34},
year = {2019},
issn = {1009-8054},
}


@article{ HBYD202407046,
author = { 何宛星 and  王宁 and  段崔林 },
title = {人工智能换脸技术带来的社会风险和对策研究},
journal = {长江信息通信},
volume = {37},
number = {07},
pages = {151-153+158},
year = {2024},
issn = {2096-9759},
doi = {10.20153/j.issn.2096-9759.2024.07.046}
}


@article{ JSGG202422005,
author = { 谢天圻 and  吴媛媛 and  敬超 and  孙伟恒 },
title = {GAN模型生成图像检测方法综述},
journal = {计算机工程与应用},
volume = {60},
number = {22},
pages = {74-86},
year = {2024},
issn = {1002-8331},
}


@article{ HZLG20241009003,
author = { 杨宏宇 and  李星航 and  胡泽 },
title = {深度伪造人脸生成与检测技术综述},
journal = {华中科技大学学报(自然科学版)},
pages = {1-19},
issn = {1671-4512},
doi = {10.13245/j.hust.250021}
}




@InProceedings{Li_2021_CVPR,
    author    = {Li, Jiaming and Xie, Hongtao and Li, Jiahong and Wang, Zhongyuan and Zhang, Yongdong},
    title     = {Frequency-Aware Discriminative Feature Learning Supervised by Single-Center Loss for Face Forgery Detection},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {6458-6467}
}


@InProceedings{Luo_2021_CVPR,
    author    = {Luo, Yuchen and Zhang, Yong and Yan, Junchi and Liu, Wei},
    title     = {Generalizing Face Forgery Detection With High-Frequency Features},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {16317-16326}
}

@inproceedings{woo2022add,
  title={Add: Frequency attention and multi-view based knowledge distillation to detect low-quality compressed deepfake images},
  author={Woo, Simon and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={1},
  pages={122--130},
  year={2022}
}



@INPROCEEDINGS{Wang2023Freq,
  author={Wang, Yuan and Yu, Kun and Chen, Chen and Hu, Xiyuan and Peng, Silong},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Dynamic Graph Learning with Content-guided Spatial-Frequency Relation Reasoning for Deepfake Detection}, 
  year={2023},
  volume={},
  number={},
  pages={7278-7287},
  keywords={Visualization;Deepfakes;Frequency-domain analysis;Benchmark testing;Feature extraction;Forgery;Cognition;Humans: Face;body;pose;gesture;movement},
  doi={10.1109/CVPR52729.2023.00703}}



  @INPROCEEDINGS{tan2024rethinking,
  author={Tan, Chuangchuang and Liu, Huan and Zhao, Yao and Wei, Shikui and Gu, Guanghua and Liu, Ping and Wei, Yunchao},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Rethinking the Up-Sampling Operations in CNN-Based Generative Network for Generalizable Deepfake Detection}, 
  year={2024},
  volume={},
  number={},
  pages={28130-28139},
  keywords={Deepfakes;Computer vision;Frequency-domain analysis;Computer architecture;Detectors;Generative adversarial networks;Generators;Deepfake Detection;Up-Sampling Operations;Neighboring Pixel Relationships},
  doi={10.1109/CVPR52733.2024.02657}
  }



  @INPROCEEDINGS{ojha2023towards,
  author={Ojha, Utkarsh and Li, Yuheng and Lee, Yong Jae},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Towards Universal Fake Image Detectors that Generalize Across Generative Models}, 
  year={2023},
  volume={},
  number={},
  pages={24480-24489},
  keywords={Training;Computer vision;Codes;Computational modeling;Buildings;Detectors;Generative adversarial networks;Image and video synthesis and generation},
  doi={10.1109/CVPR52729.2023.02345}}


  
  @INPROCEEDINGS{liu2024forgery,
  author={Liu, Huan and Tan, Zichang and Tan, Chuangchuang and Wei, Yunchao and Wang, Jingdong and Zhao, Yao},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Forgery-aware Adaptive Transformer for Generalizable Synthetic Image Detection}, 
  year={2024},
  volume={},
  number={},
  pages={10770-10780},
  keywords={Training;Couplings;Adaptation models;Detectors;Transformer cores;Transformers;Feature extraction;Synthetic Image Detection;Forgery Adaptation},
  doi={10.1109/CVPR52733.2024.01024}}




  @article{tan2024c2p,
  title={C2P-CLIP: Injecting Category Common Prompt in CLIP to Enhance Generalization in Deepfake Detection},
  author={Tan, Chuangchuang and Tao, Renshuai and Liu, Huan and Gu, Guanghua and Wu, Baoyuan and Zhao, Yao and Wei, Yunchao},
  journal={arXiv preprint arXiv:2408.09647},
  year={2024}
}



@InProceedings{Hulzebosch_2020_CVPR_Workshops,
author = {Hulzebosch, Nils and Ibrahimi, Sarah and Worring, Marcel},
title = {Detecting CNN-Generated Facial Images in Real-World Scenarios},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020}
}




@inproceedings{tan2024frequency,
  title={Frequency-Aware Deepfake Detection: Improving Generalizability through Frequency Space Domain Learning},
  author={Tan, Chuangchuang and Zhao, Yao and Wei, Shikui and Gu, Guanghua and Liu, Ping and Wei, Yunchao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={5052--5060},
  year={2024}
}


@inproceedings{jeong2022frepgan,
  title={FrePGAN: robust deepfake detection using frequency-level perturbations},
  author={Jeong, Yonghyun and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={1},
  pages={1060--1068},
  year={2022}
}



@INPROCEEDINGS{detect-photoshop,
  author={Wang, Sheng-Yu and Wang, Oliver and Zhang, Richard and Owens, Andrew and Efros, Alexei},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Detecting Photoshopped Faces by Scripting Photoshop}, 
  year={2019},
  volume={},
  number={},
  pages={10071-10080},
  keywords={Tools;Training;Flickr;Forensics;Task analysis;Image reconstruction;Visualization},
  doi={10.1109/ICCV.2019.01017}}

@INPROCEEDINGS{fusingglobalandlocal,
  author={Ju, Yan and Jia, Shan and Ke, Lipeng and Xue, Hongfei and Nagano, Koki and Lyu, Siwei},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={Fusing Global and Local Features for Generalized AI-Synthesized Image Detection}, 
  year={2022},
  volume={},
  number={},
  pages={3465-3469},
  keywords={Deepfakes;Fuses;Forensics;Detectors;Media;Feature extraction;Generative adversarial networks;AI-synthesized Image Detection;Image Forensics;Feature Fusion;Attention Mechanism},
  doi={10.1109/ICIP46576.2022.9897820}}


@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@inproceedings{karras2018progressive,
  title={Progressive Growing of {GAN}s for Improved Quality, Stability, and Variation},
  author={Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=Hk99zCeAb},
  }


  @INPROCEEDINGS{karras2019style,
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Style-Based Generator Architecture for Generative Adversarial Networks}, 
  year={2019},
  volume={},
  number={},
  pages={4396-4405},
  keywords={Deep Learning;Image and Video Synthesis; Representation Learning},
  doi={10.1109/CVPR.2019.00453}}


 @misc{face-swap,
 author = {},  
 title = {Faceswap},
 howpublished = {\url{https://faceswap.dev}},
 year = {},  
 note = {}  
}

@misc{midjourney,
author = {},  
title = {Midjourney},
howpublished = {\url{https://www.midjourney.com/}},
year = {},  
note = {}  
}


@INPROCEEDINGS{shruti2017jpeg,
  author={Agarwal, Shruti and Farid, Hany},
  booktitle={2017 IEEE Workshop on Information Forensics and Security (WIFS)}, 
  title={Photo forensics from JPEG dimples}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  keywords={Transform coding;Cameras;Discrete cosine transforms;Forensics;Image coding;Frequency-domain analysis;Quantization (signal);Image forensics;JPEG compression},
  doi={10.1109/WIFS.2017.8267641}}

@article{popescu2005exposing,
  title={Exposing digital forgeries by detecting traces of resampling},
  author={Popescu, Alin C and Farid, Hany},
  journal={IEEE Transactions on signal processing},
  volume={53},
  number={2},
  pages={758--767},
  year={2005},
  publisher={IEEE}
}


@article{obrian2012reflections,
author = {O'Brien, James F. and Farid, Hany},
title = {Exposing photo manipulation with inconsistent reflections},
year = {2012},
issue_date = {January 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0730-0301},
url = {https://doi.org/10.1145/2077341.2077345},
doi = {10.1145/2077341.2077345},
abstract = {The advent of sophisticated photo editing software has made it increasingly easier to manipulate digital images. Often visual inspection cannot definitively distinguish the resulting forgeries from authentic photographs. In response, forensic techniques have emerged to detect geometric or statistical inconsistencies that result from specific forms of photo manipulation. In this article we describe a new forensic technique that focuses on geometric inconsistencies that arise when fake reflections are inserted into a photograph or when a photograph containing reflections is manipulated. This analysis employs basic rules of reflective geometry and linear perspective projection, makes minimal assumptions about the scene geometry, and only requires the user to identify corresponding points on an object and its reflection. The analysis is also insensitive to common image editing operations such as resampling, color manipulations, and lossy compression. We demonstrate this technique with both visually plausible forgeries of our own creation and commercially produced forgeries.},
journal = {ACM Trans. Graph.},
month = feb,
articleno = {4},
numpages = {11},
keywords = {Reflections, center of projection, forgery detection, image forensics, image manipulation, mirrors, photo manipulation}
}


@INPROCEEDINGS{roessler2019faceforensicspp,
  author={Rössler, Andreas and Cozzolino, Davide and Verdoliva, Luisa and Riess, Christian and Thies, Justus and Niessner, Matthias},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={FaceForensics++: Learning to Detect Manipulated Facial Images}, 
  year={2019},
  volume={},
  number={},
  pages={1-11},
  keywords={Face;Videos;Forgery;Benchmark testing;Forensics;Three-dimensional displays;Databases},
  doi={10.1109/ICCV.2019.00009}}

  @INPROCEEDINGS {marra2018gandetection,
  author = { Marra, Francesco and Gragnaniello, Diego and Cozzolino, Davide and Verdoliva, Luisa },
  booktitle = { 2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR) },
  title = {{ Detection of GAN-Generated Fake Images over Social Networks }},
  year = {2018},
  volume = {},
  ISSN = {},
  pages = {384-389},
  abstract = { The diffusion of fake images and videos on social networks is a fast growing problem. Commercial media editing tools allow anyone to remove, add, or clone people and objects, to generate fake images. Many techniques have been proposed to detect such conventional fakes, but new attacks emerge by the day. Image-to-image translation, based on generative adversarial networks (GANs), appears as one of the most dangerous, as it allows one to modify context and semantics of images in a very realistic way. In this paper, we study the performance of several image forgery detectors against image-to-image translation, both in ideal conditions, and in the presence of compression, routinely performed upon uploading on social networks. The study, carried out on a dataset of 36302 images, shows that detection accuracies up to 95% can be achieved by both conventional and deep learning detectors, but only the latter keep providing a high accuracy, up to 89%, on compressed data. },
  keywords = {Gallium nitride;Generators;Detectors;Training;Social network services;Computer architecture;Tools},
  doi = {10.1109/MIPR.2018.00084},
  url = {https://doi.ieeecomputersociety.org/10.1109/MIPR.2018.00084},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA},
  month =apr}

  

  @InProceedings{pmlr-v119-frank20a,
  title = 	 {Leveraging Frequency Analysis for Deep Fake Image Recognition},
  author =       {Frank, Joel and Eisenhofer, Thorsten and Sch{\"o}nherr, Lea and Fischer, Asja and Kolossa, Dorothea and Holz, Thorsten},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {3247--3258},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/frank20a/frank20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/frank20a.html},
  abstract = 	 {Deep neural networks can generate images that are astonishingly realistic, so much so that it is often hard for humans to distinguish them from actual photos. These achievements have been largely made possible by Generative Adversarial Networks (GANs). While deep fake images have been thoroughly investigated in the image domain{—}a classical approach from the area of image forensics{—}an analysis in the frequency domain has been missing so far. In this paper,we address this shortcoming and our results reveal that in frequency space, GAN-generated images exhibit severe artifacts that can be easily identified. We perform a comprehensive analysis, showing that these artifacts are consistent across different neural network architectures, data sets, and resolutions. In a further investigation, we demonstrate that these artifacts are caused by upsampling operations found in all current GAN architectures, indicating a structural and fundamental problem in the way images are generated via GANs. Based on this analysis, we demonstrate how the frequency representation can be used to identify deep fake images in an automated way, surpassing state-of-the-art methods.}
}


@INPROCEEDINGS{zhang2019gan,
  author={Zhang, Xu and Karaman, Svebor and Chang, Shih-Fu},
  booktitle={2019 IEEE International Workshop on Information Forensics and Security (WIFS)}, 
  title={Detecting and Simulating Artifacts in GAN Fake Images}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  keywords={Gallium nitride;Generative adversarial networks;Convolution;Pipelines;Generators;Training;Tensors},
  doi={10.1109/WIFS47025.2019.9035107}}


  @article{cozzolino2018forensictransfer,
  title={Forensictransfer: Weakly-supervised domain adaptation for forgery detection},
  author={Cozzolino, Davide and Thies, Justus and R{\"o}ssler, Andreas and Riess, Christian and Nie{\ss}ner, Matthias and Verdoliva, Luisa},
  journal={arXiv preprint arXiv:1812.02510},
  year={2018}
}

@inproceedings{park2020swapping,
 author = {Park, Taesung and Zhu, Jun-Yan and Wang, Oliver and Lu, Jingwan and Shechtman, Eli and Efros, Alexei and Zhang, Richard},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {7198--7211},
 publisher = {Curran Associates, Inc.},
 title = {Swapping Autoencoder for Deep Image Manipulation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/50905d7b2216bfeccb5b41016357176b-Paper.pdf},
 volume = {33},
 year = {2020}
}


@misc{deepfakelab,
  author = {},  
  title = {DeepFaceLab},
  howpublished = {\url{https://github.com/iperov/DeepFaceLab}},
  year = {}, 
  note = {}  
}


@misc{dfaker,
 author = {},
 title = {DFaker},
 howpublished = {\url{https://github.com/dfaker/df}},
 note = {},
 year = {}
}




@INPROCEEDINGS{stylegan,
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Style-Based Generator Architecture for Generative Adversarial Networks}, 
  year={2019},
  volume={},
  number={},
  pages={4396-4405},
  keywords={Deep Learning;Image and Video Synthesis; Representation Learning},
  doi={10.1109/CVPR.2019.00453}}


  @article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@INPROCEEDINGS{rombach2022high,
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
  year={2022},
  volume={},
  number={},
  pages={10674-10685},
  keywords={Training;Visualization;Image synthesis;Computational modeling;Noise reduction;Superresolution;Process control;Image and video synthesis and generation},
  doi={10.1109/CVPR52688.2022.01042}}

  @inproceedings{brock2018large,
  title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
  author={Andrew Brock and Jeff Donahue and Karen Simonyan},
  booktitle={International Conference on Learning Representations},
  year={2019},
  url={https://openreview.net/forum?id=B1xsqj09Fm},
  }



  @article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}


@INPROCEEDINGS{ldm,
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
  year={2022},
  volume={},
  number={},
  pages={10674-10685},
  keywords={Training;Visualization;Image synthesis;Computational modeling;Noise reduction;Superresolution;Process control;Image and video synthesis and generation},
  doi={10.1109/CVPR52688.2022.01042}}


  @InProceedings{glide,
  title = 	 {{GLIDE}: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
  author =       {Nichol, Alexander Quinn and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and Mcgrew, Bob and Sutskever, Ilya and Chen, Mark},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {16784--16804},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/nichol22a/nichol22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/nichol22a.html},
  abstract = 	 {Diffusion models have recently been shown to generate high-quality synthetic images, especially when paired with a guidance technique to trade off diversity for fidelity. We explore diffusion models for the problem of text-conditional image synthesis and compare two different guidance strategies: CLIP guidance and classifier-free guidance. We find that the latter is preferred by human evaluators for both photorealism and caption similarity, and often produces photorealistic samples. Samples from a 3.5&nbsp;billion parameter text-conditional diffusion model using classifier-free guidance are favored by human evaluators to those from DALL-E, even when the latter uses expensive CLIP reranking. Additionally, we find that our models can be fine-tuned to perform image inpainting, enabling powerful text-driven image editing. We train a smaller model on a filtered dataset and release the code and weights at https://github.com/openai/glide-text2im.}
}


@INPROCEEDINGS{li-cvpr2020,
  author={Li, Yuheng and Singh, Krishna Kumar and Ojha, Utkarsh and Lee, Yong Jae},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MixNMatch: Multifactor Disentanglement and Encoding for Conditional Image Generation}, 
  year={2020},
  volume={},
  number={},
  pages={8036-8045},
  keywords={Shape;Image generation;Generators;Birds;Training;Aerospace electronics;Detectors},
  doi={10.1109/CVPR42600.2020.00806}}

  @InProceedings{Wang_2020_CVPR,
  author = {Wang, Sheng-Yu and Wang, Oliver and Zhang, Richard and Owens, Andrew and Efros, Alexei A.},
  title = {CNN-Generated Images Are Surprisingly Easy to Spot... for Now},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2020}
  }
  

  @article{yu2015lsun,
  title={Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop},
  author={Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  journal={arXiv preprint arXiv:1506.03365},
  year={2015}
}

@inproceedings{chai2020makes,
  title={What makes fake images detectable? understanding properties that generalize},
  author={Chai, Lucy and Bau, David and Lim, Ser-Nam and Isola, Phillip},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXVI 16},
  pages={103--120},
  year={2020},
  organization={Springer}
}

@INPROCEEDINGS{jeong2022bihpf,
  author={Jeong, Yonghyun and Kim, Doyeon and Min, Seungjai and Joe, Seongho and Gwon, Youngjune and Choi, Jongwon},
  booktitle={2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={BiHPF: Bilateral High-Pass Filters for Robust Deepfake Detection}, 
  year={2022},
  volume={},
  number={},
  pages={2878-2887},
  keywords={Training;Frequency synthesizers;Image resolution;Image coding;Image color analysis;Computational modeling;Data models;Vision Systems and Applications Deep Learning -> Adversarial Learning; Adversarial Attack and Defense Methods; Deep Learning -> Neural Generative Models; Autoencoders; GANs; Security/Surveillance},
  doi={10.1109/WACV51458.2022.00293}}


  @InProceedings{Schwarcz_2021_CVPR,
  author    = {Schwarcz, Steven and Chellappa, Rama},
  title     = {Finding Facial Forgery Artifacts With Parts-Based Detectors},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  month     = {June},
  year      = {2021},
  pages     = {933-942}
}


@INPROCEEDINGS{Tan_2023_CVPR,
  author={Tan, Chuangchuang and Zhao, Yao and Wei, Shikui and Gu, Guanghua and Wei, Yunchao},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Learning on Gradients: Generalized Artifacts Representation for GAN-Generated Images Detection}, 
  year={2023},
  volume={},
  number={},
  pages={12105-12114},
  keywords={Deepfakes;Computer vision;Codes;Image synthesis;Computational modeling;Detectors;Robustness;Recognition: Categorization;detection;retrieval},
  doi={10.1109/CVPR52729.2023.01165}}



  @InProceedings{pmlr-v119-frank20a,
  title = 	 {Leveraging Frequency Analysis for Deep Fake Image Recognition},
  author =       {Frank, Joel and Eisenhofer, Thorsten and Sch{\"o}nherr, Lea and Fischer, Asja and Kolossa, Dorothea and Holz, Thorsten},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {3247--3258},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/frank20a/frank20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/frank20a.html},
  abstract = 	 {Deep neural networks can generate images that are astonishingly realistic, so much so that it is often hard for humans to distinguish them from actual photos. These achievements have been largely made possible by Generative Adversarial Networks (GANs). While deep fake images have been thoroughly investigated in the image domain{—}a classical approach from the area of image forensics{—}an analysis in the frequency domain has been missing so far. In this paper,we address this shortcoming and our results reveal that in frequency space, GAN-generated images exhibit severe artifacts that can be easily identified. We perform a comprehensive analysis, showing that these artifacts are consistent across different neural network architectures, data sets, and resolutions. In a further investigation, we demonstrate that these artifacts are caused by upsampling operations found in all current GAN architectures, indicating a structural and fundamental problem in the way images are generated via GANs. Based on this analysis, we demonstrate how the frequency representation can be used to identify deep fake images in an automated way, surpassing state-of-the-art methods.}
}



@InProceedings{Durall_2020_CVPR,
author = {Durall, Ricard and Keuper, Margret and Keuper, Janis},
title = {Watch Your Up-Convolution: CNN Based Generative Deep Neural Networks Are Failing to Reproduce Spectral Distributions},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@InProceedings{Masi,
author="Masi, Iacopo
and Killekar, Aditya
and Mascarenhas, Royston Marian
and Gurudatt, Shenoy Pratik
and AbdAlmageed, Wael",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Two-Branch Recurrent Network for Isolating Deepfakes in Videos",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="667--684",
abstract="The current spike of hyper-realistic faces artificially generated using deepfakes calls for media forensics solutions that are tailored to video streams and work reliably with a low false alarm rate at the video level. We present a method for deepfake detection based on a two-branch network structure that isolates digitally manipulated faces by learning to amplify artifacts while suppressing the high-level face content. Unlike current methods that extract spatial frequencies as a preprocessing step, we propose a two-branch structure: one branch propagates the original information, while the other branch suppresses the face content yet amplifies multi-band frequencies using a Laplacian of Gaussian (LoG) as a bottleneck layer. To better isolate manipulated faces, we derive a novel cost function that, unlike regular classification, compresses the variability of natural faces and pushes away the unrealistic facial samples in the feature space. Our two novel components show promising results on the FaceForensics+ +, Celeb-DF, and Facebook's DFDC preview benchmarks, when compared to prior work. We then offer a full, detailed ablation study of our network architecture and cost function. Finally, although the bar is still high to get very remarkable figures at a very low false alarm rate, our study shows that we can achieve good video-level performance when cross-testing in terms of video-level AUC.",
isbn="978-3-030-58571-6"
}


@InProceedings{YuyangQian,
author="Qian, Yuyang
and Yin, Guojun
and Sheng, Lu
and Chen, Zixuan
and Shao, Jing",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Thinking in Frequency: Face Forgery Detection by Mining Frequency-Aware Clues",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="86--103",
abstract="As realistic facial manipulation technologies have achieved remarkable progress, social concerns about potential malicious abuse of these technologies bring out an emerging research topic of face forgery detection. However, it is extremely challenging since recent advances are able to forge faces beyond the perception ability of human eyes, especially in compressed images and videos. We find that mining forgery patterns with the awareness of frequency could be a cure, as frequency provides a complementary viewpoint where either subtle forgery artifacts or compression errors could be well described. To introduce frequency into the face forgery detection, we propose a novel Frequency in Face Forgery Network (F{\$}{\$}^3{\$}{\$}3-Net), taking advantages of two different but complementary frequency-aware clues, 1) frequency-aware decomposed image components, and 2) local frequency statistics, to deeply mine the forgery patterns via our two-stream collaborative learning framework. We apply DCT as the applied frequency-domain transformation. Through comprehensive studies, we show that the proposed F{\$}{\$}^3{\$}{\$}3-Net significantly outperforms competing state-of-the-art methods on all compression qualities in the challenging FaceForensics++ dataset, especially wins a big lead upon low-quality media.",
isbn="978-3-030-58610-2"
}



@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8110--8119},
  year={2020}
}




@inproceedings{CycleGAN,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and others},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2223--2232},
  year={2017}
}


@inproceedings{choi2018stargan,
  title={Stargan: Unified generative adversarial networks for multi-domain image-to-image translation},
  author={Choi, Yunjey and others},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8789--8797},
  year={2018}
}


@inproceedings{GauGAN,
  title={Semantic image synthesis with spatially-adaptive normalization},
  author={Park, Taesung and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2337--2346},
  year={2019}
}


@inproceedings{Deepfake,
  title={Faceforensics++: Learning to detect manipulated facial images},
  author={Rossler, Andreas and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1--11},
  year={2019}
}



@article{russakovsky2015imagenet,
  title={Imagenet large scale visual Recognition challenge},
  author={Russakovsky, Olga and others},
  journal={International Journal of Computer Vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}



@inproceedings{CelebA,
  title={Deep learning face attributes in the wild},
  author={Liu, Ziwei and others},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3730--3738},
  year={2015}
}




@inproceedings{coco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and others},
  booktitle={European Conference on Computer Vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}


@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={Pmlr}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}


@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}


@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}



@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{hinton2006fast,
  title={A fast learning algorithm for deep belief nets},
  author={Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  journal={Neural computation},
  volume={18},
  number={7},
  pages={1527--1554},
  year={2006},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group UK London}
}



@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and others},
  booktitle={ICML},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}










































































@INPROCEEDINGS{cnproceed,
	author    = {王重阳 and 黄药师 and 欧阳峰 and 洪七公 and 段皇帝},
	title     = {武林高手从入门到精通},
	booktitle = {第~$N$~次华山论剑},
	year      = 2006,
	address   = {西安, 中国},
	month     = sep,
	language   ="zh",
}

@ARTICLE{cnarticle,
	AUTHOR  = "贾宝玉 and 林黛玉 and 薛宝钗 and 贾探春",
	TITLE   = "论刘姥姥食量大如牛之现实意义",
	JOURNAL = "红楼梦杂谈",
	PAGES   = "260-266",
	VOLUME  = "224",
	YEAR    = "1800",
	language   ="zh",
}


@inbook{Lin1992,
	language   ="zh",
	AUTHOR     = "林来兴",
	TITLE      = "空间控制技术",
	PUBLISHER  = "宇航出版社",
	YEAR       = "1992",
	Pages      = "25-42",
	ADDRESS    = "北京",
}

@book{xin1994,
	language   ="zh",
	title={信息技术与信息服务国际研讨会论文集},
	author={辛希孟 and 中国科学院文献信息中心 and 孟广均 and 信息学},
	year={1994},
	publisher={中国社会科学出版社},
	pages={45-49},
	address={北京},
	typeoflit={C},
}

@book{zhao1998,
	language   ="zh",
	title={新时代的工业工程师},
	author={赵耀东},
	year={1998},
	citedate =     {1998-09-26},
	address={台北},
	publisher={天下文化出版社},
	url={http://www.ie.nthu.edu.tw/info/ie.newie.htm(Big5)},
	typeoflit={M/OL},
}

@phdthesis{Chen1992,
	language   ="zh",
	Author = {谌颖},
	Title = {空间最优交会控制理论与方法研究},
	ADDRESS    = "哈尔滨",
	School = {哈尔滨工业大学},
	Year = {1992},
	pages= {8-13},
}

@article{hithesis2017,
	title={Hi!Thesis!,Harbin Institue of Technology},
	author={Yanshuo Chu},
	journal={Github},
	volume={001},
	number={0001},
	pages={000-999},
	year={2017},
}
